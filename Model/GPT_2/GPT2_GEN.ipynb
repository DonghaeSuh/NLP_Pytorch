{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1jLd3fgb_ouffcYMR_qbngEdXeBW7cdyx",
      "authorship_tag": "ABX9TyOYMH60Ejw4Lbb6XT84lmS0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DonghaeSuh/NLP_Pytorch/blob/main/Model/GPT_2/GPT2_GEN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sentencepiece : https://github.com/google/sentencepiece/blob/master/python/README.md"
      ],
      "metadata": {
        "id": "e33Dl5K-J_8S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### NSMC"
      ],
      "metadata": {
        "id": "GC2mkEpqPcB8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib"
      ],
      "metadata": {
        "id": "GAhQpLHSKpwQ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "urllib.request.urlretrieve('https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt','train.txt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZGWRVyXKZjN",
        "outputId": "9f6f952c-a9b9-4a8b-85c4-7d28e069cd1f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('train.txt', <http.client.HTTPMessage at 0x7b4c5cefc220>)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp=[]"
      ],
      "metadata": {
        "id": "_D-LYLxqLhUP"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('train.txt','r') as f:\n",
        "  f.readline()\n",
        "  for sent in f.readlines():\n",
        "    data = sent.split('\\t')\n",
        "    temp.append(data[1])"
      ],
      "metadata": {
        "id": "KRfZtCCTK8ht"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(temp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Crf3PXHL7x8",
        "outputId": "afff9864-c9cd-417c-a56b-5f95920e3197"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "150000"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd drive/MyDrive/Pytorch\\ NLP/GPT-2/data_in/gpt2_ckpt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LG3ehNgKKuDL",
        "outputId": "7bbab2e2-f386-42b9-cfd1-11f59f48c1ec"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Pytorch NLP/GPT-2/data_in/gpt2_ckpt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('corpus.txt','w') as f:\n",
        "  for sent in temp:\n",
        "    f.write(f'\\n {sent}')"
      ],
      "metadata": {
        "id": "NaCJp9IsLLiV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sentencepiece"
      ],
      "metadata": {
        "id": "B2LJdAsrPbf7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://keep-steady.tistory.com/7"
      ],
      "metadata": {
        "id": "mBkBxNqCSM2-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install sentencepiece"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APOTeyaOOQYb",
        "outputId": "5851252d-2568-4f63-82b4-be4a6e0b3ccd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sentencepiece as spm"
      ],
      "metadata": {
        "id": "ZayDEQQtPgz3"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spm.SentencePieceTrainer.train(input='corpus.txt',model_prefix='kor_tokenizer',vocab_size=50257, model_type='bpe',max_sentence_length=9999999,pad_id=0,unk_id=1,bos_id=2,eos_id=3)"
      ],
      "metadata": {
        "id": "Z8G5cAI3PpbL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenizer"
      ],
      "metadata": {
        "id": "bCjotYQ6U329"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sp=spm.SentencePieceProcessor()\n",
        "sp.Load('kor_tokenizer.model')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "quvfnYo9rqdD",
        "outputId": "cef09f4a-f1de-4edf-ada5-69632123a24a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sp.EncodeAsPieces('안녕하세요 저는 사람이에요.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MdcRqlOLrYr-",
        "outputId": "cf75babd-d52e-4ea5-f0a1-6347fc65536b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['▁안녕하세요', '▁저는', '▁사람이', '에요', '.']"
            ]
          },
          "metadata": {},
          "execution_count": 238
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sp.encode('안녕하세요 저는 사람이에요.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9ZNdSMwsE1T",
        "outputId": "8b9e3e60-badb-494e-f3bc-1c8f47f8dfdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[20363, 1619, 1047, 802, 48546]"
            ]
          },
          "metadata": {},
          "execution_count": 239
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sp.encode('그래')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2eT_jqTlkfT0",
        "outputId": "8c0791eb-d787-4c11-aea0-257506f80bab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[312]"
            ]
          },
          "metadata": {},
          "execution_count": 240
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sp.bos_id()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fvfou9ZbktX3",
        "outputId": "b70565ed-c8c3-49ac-c14c-30f1abdfb1ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 241
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = [sp.id_to_piece(id) for id in range(sp.get_piece_size())]"
      ],
      "metadata": {
        "id": "G4ZIARzH8IM9"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('0 :{}, 1 :{} , 2 :{}, 3 :{} '.format(vocab[0],vocab[1],vocab[2],vocab[3]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uf1TMOXiioo2",
        "outputId": "5f85aa86-6ce1-4a53-c4db-37a758a2b2a1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 :<pad>, 1 :<unk> , 2 :<s>, 3 :</s> \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Input for fine-tuning"
      ],
      "metadata": {
        "id": "EnUMRMLQwt3r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### filtering"
      ],
      "metadata": {
        "id": "VxowShiSyv5G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "Q5B8v-HhxFbE"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp[5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "CMQA27SOx1jR",
        "outputId": "decb8460-d58d-4324-ab73-674199b182da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'막 걸음마 뗀 3세부터 초등학교 1학년생인 8살용영화.ㅋㅋㅋ...별반개도 아까움.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_sent = [ ' '.join((re.sub('[^ㄱ-ㅎ가-힣0-9 ]',' ',sent)).split()) for sent in temp]"
      ],
      "metadata": {
        "id": "Wop314V0w367"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_sent[5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "GTlyEk2Hxnv-",
        "outputId": "7a723ceb-759d-4bdc-e80c-1e9be80cd3c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'막 걸음마 뗀 3세부터 초등학교 1학년생인 8살용영화 ㅋㅋㅋ 별반개도 아까움'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### padding and truncation"
      ],
      "metadata": {
        "id": "OoKIFQIhy7wu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "t9pzX7r4y6_F"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_len=[len(sp.encode(sent)) for sent in filtered_sent ]"
      ],
      "metadata": {
        "id": "XWNRSipb0CwK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('3사분위 길이 :{}'.format(np.percentile(tokenized_len,99)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8EYC0ibBzC_W",
        "outputId": "40fedf52-7f04-4e32-84aa-f40ca1ac2182"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3사분위 길이 :47.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[0]*10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qB7VP8_woXzo",
        "outputId": "3568d412-21df-42e3-d6f2-af02496809ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN=47"
      ],
      "metadata": {
        "id": "viy2W_q5mM0k"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "ka_qkUUAp7Ei"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_input_output(input,max_len):\n",
        "  # input : (samples, sent_len)\n",
        "\n",
        "  train_input=[]\n",
        "  train_output=[]\n",
        "\n",
        "  # append <s>, </s>, <pad>\n",
        "  for sent in input:\n",
        "    if len(sp.encode(sent))<max_len:\n",
        "      pad_len = max_len-len(sp.encode(sent))-1\n",
        "      train_input.append([sp.bos_id()]+sp.encode(sent)+[sp.pad_id()]*pad_len)\n",
        "      train_output.append(sp.encode(sent)+[sp.eos_id()]+[sp.pad_id()]*pad_len)\n",
        "    else: # truncation\n",
        "      train_input.append([sp.bos_id()]+sp.encode(sent)[:max_len-1])\n",
        "      train_output.append(sp.encode(sent)[:max_len-1]+[sp.eos_id()])\n",
        "\n",
        "  return torch.LongTensor(train_input), torch.LongTensor(train_output) # (samples, max_len)"
      ],
      "metadata": {
        "id": "vd_P_Hp3mSYx"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_input, train_output = preprocess_input_output(filtered_sent,MAX_LEN)"
      ],
      "metadata": {
        "id": "mPjclEZApuzF"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_input[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6pNb_feqHEO",
        "outputId": "4a8d27d0-3133-4cbb-daae-9c7ab1a52e81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([    2,     8,  1080,    55, 17382,  2106,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_output[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ow_AgLq0qa63",
        "outputId": "50df4070-ac03-49e3-df93-2ae8b681e31f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([    8,  1080,    55, 17382,  2106,     3,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset,DataLoader"
      ],
      "metadata": {
        "id": "UrALBW-GqeDu"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "  def __init__(self,x,y):\n",
        "    self.x=x\n",
        "    self.y=y\n",
        "\n",
        "  def __getitem__(self,index):\n",
        "    return self.x[index], self.y[index]\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.x.size()[0]"
      ],
      "metadata": {
        "id": "eNa1vjm2qjIl"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = CustomDataset(train_input,train_output)"
      ],
      "metadata": {
        "id": "DIP9A89F4G9H"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_iter = DataLoader(train_dataset,batch_size=64)"
      ],
      "metadata": {
        "id": "bBvvF-W65VcD"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(train_iter))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uujliuwn9D2w",
        "outputId": "2dbca08d-f67e-4844-c51a-77df7b99d193"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[    2,     8,  1080,  ...,     0,     0,     0],\n",
              "         [    2,  1609, 17387,  ...,     0,     0,     0],\n",
              "         [    2,    25, 48579,  ...,     0,     0,     0],\n",
              "         ...,\n",
              "         [    2,   194, 48700,  ...,     0,     0,     0],\n",
              "         [    2, 39386,  1661,  ...,     0,     0,     0],\n",
              "         [    2,  4928,  3547,  ...,     0,     0,     0]]),\n",
              " tensor([[    8,  1080,    55,  ...,     0,     0,     0],\n",
              "         [ 1609, 17387, 23046,  ...,     0,     0,     0],\n",
              "         [   25, 48579, 50166,  ...,     0,     0,     0],\n",
              "         ...,\n",
              "         [  194, 48700, 48547,  ...,     0,     0,     0],\n",
              "         [39386,  1661, 38441,  ...,     0,     0,     0],\n",
              "         [ 4928,  3547,   610,  ...,     0,     0,     0]])]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### config & model_weight"
      ],
      "metadata": {
        "id": "SgiJQ2gTQn-p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "urllib.request.urlretrieve('https://huggingface.co/gpt2/resolve/main/config.json','config.json')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EeqjKoUcQs2X",
        "outputId": "f4630f7e-722f-490c-98ca-fb15eaf06473"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('config.json', <http.client.HTTPMessage at 0x7fdd07c1ada0>)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "urllib.request.urlretrieve('https://huggingface.co/gpt2/resolve/main/model.safetensors','model.safetensors')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXbpfCuvRWr2",
        "outputId": "fe5048c1-24e1-4700-cc03-420c0ad62500"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('model.safetensors', <http.client.HTTPMessage at 0x7fdd07c19ed0>)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Top k & Top p"
      ],
      "metadata": {
        "id": "0kjeBZ0bOhhq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### torch.multinomial"
      ],
      "metadata": {
        "id": "tuhXFcHsBYNK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "SP56xQAnBlXK"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def top_k_top_p_filtering(logits, top_k=0, top_p=0.0, filter_value=-99999):\n",
        "  # logits = (vocab_size, )\n",
        "\n",
        "  if top_k>0:\n",
        "    top_k=min(top_k,logits.size()[0])\n",
        "    indices_to_remove=logits<torch.topk(logits,top_k).values[-1] # smaller than the smallest value among the top_k values\n",
        "    logits[indices_to_remove]=filter_value\n",
        "\n",
        "  if top_p>0.0:\n",
        "    sorted_logits=torch.sort(logits,descending=True)\n",
        "    sorted_logits_index=torch.argsort(logits,descending=True)\n",
        "    prob_cumsum = torch.cumsum(nn.Softmax()(sorted_logits))\n",
        "\n",
        "    sorted_indices_to_remove=prob_cumsum>top_p\n",
        "    sorted_indices_to_remove=torch.cat([torch.LongTensor([False]),sorted_indices_to_remove[:-1]]) # prevent if first is True\n",
        "    indices_to_remove = sorted_logits_index[sorted_indices_to_remove]\n",
        "\n",
        "    logits[indices_to_remove]=filter_value\n",
        "\n",
        "  return logits   # logits = (vocab_size, )\n"
      ],
      "metadata": {
        "id": "Y3gxMcb8OxxL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Greedy & Generate_sentence Function"
      ],
      "metadata": {
        "id": "-c0qYyVEqaoU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_sent(seed_word,model,max_len=100,greedy=False,top_k=0,top_p=0.0):\n",
        "  sent= seed_word\n",
        "  toked = sp.encode(sent)\n",
        "\n",
        "  for _ in range(max_len):\n",
        "    input_ids = torch.LongTensor([sp.bos_id()]+toked)[None,:] # input_ids = (1, cumulated_seq_len)\n",
        "    outputs = model(input_ids)[0,-1,:] # outputs : (vocab_size, )\n",
        "\n",
        "    if greedy:\n",
        "      gen = sp.id_to_piece(outputs.argmax().tolist()) # outputs.argmax().tolist() -> int\n",
        "    else:\n",
        "      output_logits = top_k_top_p_filtering(outputs,top_k,top_p) # logits = (vocab_size, )\n",
        "      gen = torch.multinomial(nn.Softmax(-1)(output_logits),num_samples=1,replacement=True).tolist()[0]\n",
        "      gen = sp.id_to_piece(gen)\n",
        "    if gen == '</s>':\n",
        "      break\n",
        "\n",
        "    sent+=gen.replace('▁',' ')\n",
        "    toked=sp.encode(sent)\n",
        "\n",
        "  return sent"
      ],
      "metadata": {
        "id": "7FD4jcD3eLBS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Huggingface Transformers"
      ],
      "metadata": {
        "id": "2tF56U0HqZSs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Au-SM5_crBt4",
        "outputId": "09c9f42c-5d61-48bc-e74d-329fff48722d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Pytorch NLP/GPT-2/data_in\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers"
      ],
      "metadata": {
        "id": "uG_2d-qWo3Nq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b7491e2-1f89-4d3e-e29d-1a87615f14fa"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.16.4 safetensors-0.3.1 tokenizers-0.13.3 transformers-4.31.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2LMHeadModel"
      ],
      "metadata": {
        "id": "oVRNhprurFxi"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Pre-training"
      ],
      "metadata": {
        "id": "GPOoiqIA7Fd5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GPT2Gen(nn.Module):\n",
        "  def __init__(self,dir_path):\n",
        "    super(GPT2Gen,self).__init__()\n",
        "    self.gpt2 = GPT2LMHeadModel.from_pretrained(dir_path,ignore_mismatched_sizes=True)\n",
        "\n",
        "  def forward(self,x):\n",
        "    outputs=self.gpt2(x)[0]\n",
        "    return torch.transpose(outputs,2,1) # (batch_size=1, vocab_size, max_len)"
      ],
      "metadata": {
        "id": "nz33hkvr74Tv"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameter\n",
        "MAX_LEN=47\n",
        "BATCH_SIZE=64\n",
        "EPOCHS=10\n",
        "\n",
        "device='cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "093hz24Q8fN3"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GPT2Gen('./data_in/gpt2_ckpt').to(device)\n",
        "criterion = torch.nn.CrossEntropyLoss(reduction='none')\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=3e-5)"
      ],
      "metadata": {
        "id": "bcTT4Y-U7-nG"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "8dwuo8L69JBP"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a=torch.Tensor([[1,1,1,0,0],[1,1,0,0,0]])\n",
        "mask=~(a==0)\n",
        "\n",
        "b=torch.Tensor([[3,2,5,0,0],[1,5,3,1,0]])\n",
        "(b*mask).sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ucore8EoA3D_",
        "outputId": "1fa6dbd5-f68d-4810-aebd-76029fe49bb3"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(16.)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_loss(outputs,y,criterion):\n",
        "  loss = criterion(outputs,y) # (batch_size, max_len)\n",
        "  mask = ~(y==0)\n",
        "\n",
        "  return (loss*mask).sum()"
      ],
      "metadata": {
        "id": "SwvBnFth_7Ml"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model,optimizer,criterion,train_iter):\n",
        "  model.train()\n",
        "\n",
        "  total_loss = 0\n",
        "  for batch in tqdm(train_iter):\n",
        "    x=batch[0].to(device)\n",
        "    y=batch[1].to(device)\n",
        "\n",
        "    outputs = model(x) # outputs : (batch_size, vocab_size, max_len)\n",
        "    loss = compute_loss(outputs,y,criterion) # (batch_size, max_len )\n",
        "    total_loss+=loss\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  return total_loss/len(train_iter)"
      ],
      "metadata": {
        "id": "U3W9CSsX75MN"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "88Ea4Y_vEPqw"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_loss = None\n",
        "\n",
        "for e in range(EPOCHS):\n",
        "  avg_loss=train(model,optimizer,criterion,train_iter)\n",
        "  print('avg_loss : {}'.format(avg_loss))\n",
        "\n",
        "  if not best_loss or avg_loss<best_loss:\n",
        "    os.makedirs('./data_out/best_model')\n",
        "    torch.save(model.state_dict(),'./data_out/best_model/best_weight.pt')\n",
        "    best_loss=avg_loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 516
        },
        "id": "zfnyJcctCc-t",
        "outputId": "421b6b8c-d270-40af-93b1-b9722f7ccfe2"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/2344 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-73-fc12911823f8>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mavg_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'avg_loss : {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavg_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-64-a1364b85c380>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, criterion, train_iter)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# outputs : (batch_size, vocab_size, max_len)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (batch_size, max_len )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mtotal_loss\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-60-78c50dc78938>\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(outputs, y, criterion)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (batch_size, max_len)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m~\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1174\u001b[0;31m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0m\u001b[1;32m   1175\u001b[0m                                \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                label_smoothing=self.label_smoothing)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3027\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3028\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3029\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 578.00 MiB (GPU 0; 14.75 GiB total capacity; 13.26 GiB already allocated; 250.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Generative Model"
      ],
      "metadata": {
        "id": "4JZU6PS-rdS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TK5seQ5Qr8eI",
        "outputId": "7961c4e7-4ebb-4fc5-9505-8348184ff93c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Pytorch NLP/GPT-2/data_in\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GPT2Gen(nn.Module):\n",
        "  def __init__(self,dir_path):\n",
        "    super(GPT2Gen,self).__init__()\n",
        "    self.gpt2 = GPT2LMHeadModel.from_pretrained(dir_path,ignore_mismatched_sizes=True)\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.gpt2(x)[0] # (batch_size=1, cumulated_seq_len, vocab_size =500257)"
      ],
      "metadata": {
        "id": "O-FSehzxrOCz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpt2_model = GPT2Gen('./data_in/gpt2_ckpt')"
      ],
      "metadata": {
        "id": "5H6yvm_Jsdw3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate_sentences"
      ],
      "metadata": {
        "id": "slaZ1EEntEWj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generate_sent('안녕',gpt2_model,top_k=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "TK_KLic3tB6P",
        "outputId": "a5428767-a406-4e84-a858-f17fab9cc48e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-195-c286d1860d07>:13: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  gen = torch.multinomial(nn.Softmax()(output_logits),num_samples=1,replacement=True).tolist()[0]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'안녕 행복하길 바쁘노릇실상 귀여트랑실상 협주곡실상실상 협주곡 귀여태격태격태격 행복하길 있었는지 귀여실상실상 귀여 협주곡 무료영화 니가 귀여실상 귀여트랑 무료영화트랑트랑태격 귀여실상실상 귀여딩딩태격 니가 협주곡트랑태격태격실상 무료영화실상실상실상실상트랑 협주곡실상 바쁘 니가 가고싶실상실상실상 바쁘트랑태격 협주곡실상실상 기대되네요트랑실상실상 협주곡실상실상실상실상실상실상높음 협주곡실상 가고싶 바쁘 단어에실상트랑실상 단어에 짜맞추 협주곡실상 단어에트랑트랑 협주곡 협주곡 바쁘트랑트랑 짜맞추실상 바쁘'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 196
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mxImBf-LtQwz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}