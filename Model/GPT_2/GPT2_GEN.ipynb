{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1jLd3fgb_ouffcYMR_qbngEdXeBW7cdyx",
      "authorship_tag": "ABX9TyNX4y4SVIQJldnr2LlfUQHh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DonghaeSuh/NLP_Pytorch/blob/main/Model/GPT_2/GPT2_GEN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sentencepiece : https://github.com/google/sentencepiece/blob/master/python/README.md"
      ],
      "metadata": {
        "id": "e33Dl5K-J_8S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### NSMC"
      ],
      "metadata": {
        "id": "GC2mkEpqPcB8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib"
      ],
      "metadata": {
        "id": "GAhQpLHSKpwQ"
      },
      "execution_count": 229,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "urllib.request.urlretrieve('https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt','train.txt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZGWRVyXKZjN",
        "outputId": "da329027-6296-476a-eff3-a3a6669b8479"
      },
      "execution_count": 230,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('train.txt', <http.client.HTTPMessage at 0x77fbd5b64850>)"
            ]
          },
          "metadata": {},
          "execution_count": 230
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp=[]"
      ],
      "metadata": {
        "id": "_D-LYLxqLhUP"
      },
      "execution_count": 231,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('train.txt','r') as f:\n",
        "  f.readline()\n",
        "  for sent in f.readlines():\n",
        "    data = sent.split('\\t')\n",
        "    temp.append(data[1])"
      ],
      "metadata": {
        "id": "KRfZtCCTK8ht"
      },
      "execution_count": 232,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd drive/MyDrive/Pytorch\\ NLP/GPT-2/data_in/gpt2_ckpt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LG3ehNgKKuDL",
        "outputId": "1b2d1b32-ddad-44db-b550-6743fbc1dd0f"
      },
      "execution_count": 226,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Pytorch NLP/GPT-2/data_in/gpt2_ckpt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('corpus.txt','w') as f:\n",
        "  for sent in temp:\n",
        "    f.write(f'\\n {sent}')"
      ],
      "metadata": {
        "id": "NaCJp9IsLLiV"
      },
      "execution_count": 233,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sentencepiece"
      ],
      "metadata": {
        "id": "B2LJdAsrPbf7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://keep-steady.tistory.com/7"
      ],
      "metadata": {
        "id": "mBkBxNqCSM2-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install sentencepiece"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APOTeyaOOQYb",
        "outputId": "83372ebf-f406-440d-e0bb-e770318e2290"
      },
      "execution_count": 212,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sentencepiece as spm"
      ],
      "metadata": {
        "id": "ZayDEQQtPgz3"
      },
      "execution_count": 234,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " spm.SentencePieceTrainer.train(input='corpus.txt',model_prefix='kor_tokenizer',vocab_size=50257, model_type='bpe',max_sentence_length=9999999,pad_id=0,unk_id=1,bos_id=2,eos_id=3)"
      ],
      "metadata": {
        "id": "Z8G5cAI3PpbL"
      },
      "execution_count": 235,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### gluonnlp"
      ],
      "metadata": {
        "id": "bCjotYQ6U329"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sp=spm.SentencePieceProcessor()\n",
        "sp.Load('kor_tokenizer.model')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "quvfnYo9rqdD",
        "outputId": "604c1195-0512-43b5-8502-71ec24027155"
      },
      "execution_count": 237,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 237
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sp.EncodeAsPieces('안녕하세요 저는 사람이에요.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MdcRqlOLrYr-",
        "outputId": "cf75babd-d52e-4ea5-f0a1-6347fc65536b"
      },
      "execution_count": 238,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['▁안녕하세요', '▁저는', '▁사람이', '에요', '.']"
            ]
          },
          "metadata": {},
          "execution_count": 238
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sp.encode('안녕하세요 저는 사람이에요.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9ZNdSMwsE1T",
        "outputId": "8b9e3e60-badb-494e-f3bc-1c8f47f8dfdd"
      },
      "execution_count": 239,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[20363, 1619, 1047, 802, 48546]"
            ]
          },
          "metadata": {},
          "execution_count": 239
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sp.encode('그래')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2eT_jqTlkfT0",
        "outputId": "8c0791eb-d787-4c11-aea0-257506f80bab"
      },
      "execution_count": 240,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[312]"
            ]
          },
          "metadata": {},
          "execution_count": 240
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sp.bos_id()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fvfou9ZbktX3",
        "outputId": "b70565ed-c8c3-49ac-c14c-30f1abdfb1ef"
      },
      "execution_count": 241,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 241
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = [sp.id_to_piece(id) for id in range(sp.get_piece_size())]"
      ],
      "metadata": {
        "id": "G4ZIARzH8IM9"
      },
      "execution_count": 242,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('0 :{}, 1 :{} , 2 :{}, 3 :{} '.format(vocab[0],vocab[1],vocab[2],vocab[3]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uf1TMOXiioo2",
        "outputId": "a3121e55-f620-4de8-dd32-24d82536f04b"
      },
      "execution_count": 243,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 :<pad>, 1 :<unk> , 2 :<s>, 3 :</s> \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### config & model_weight"
      ],
      "metadata": {
        "id": "SgiJQ2gTQn-p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "urllib.request.urlretrieve('https://huggingface.co/gpt2/resolve/main/config.json','config.json')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EeqjKoUcQs2X",
        "outputId": "f4630f7e-722f-490c-98ca-fb15eaf06473"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('config.json', <http.client.HTTPMessage at 0x7fdd07c1ada0>)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "urllib.request.urlretrieve('https://huggingface.co/gpt2/resolve/main/model.safetensors','model.safetensors')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXbpfCuvRWr2",
        "outputId": "fe5048c1-24e1-4700-cc03-420c0ad62500"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('model.safetensors', <http.client.HTTPMessage at 0x7fdd07c19ed0>)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Top k & Top p"
      ],
      "metadata": {
        "id": "0kjeBZ0bOhhq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### torch.multinomial"
      ],
      "metadata": {
        "id": "tuhXFcHsBYNK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "SP56xQAnBlXK"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def top_k_top_p_filtering(logits, top_k=0, top_p=0.0, filter_value=-99999):\n",
        "  # logits = (vocab_size, )\n",
        "\n",
        "  if top_k>0:\n",
        "    top_k=min(top_k,logits.size()[0])\n",
        "    indices_to_remove=logits<torch.topk(logits,top_k).values[-1] # smaller than the smallest value among the top_k values\n",
        "    logits[indices_to_remove]=filter_value\n",
        "\n",
        "  if top_p>0.0:\n",
        "    sorted_logits=torch.sort(logits,descending=True)\n",
        "    sorted_logits_index=torch.argsort(logits,descending=True)\n",
        "    prob_cumsum = torch.cumsum(nn.Softmax()(sorted_logits))\n",
        "\n",
        "    sorted_indices_to_remove=prob_cumsum>top_p\n",
        "    sorted_indices_to_remove=torch.cat([torch.LongTensor([False]),sorted_indices_to_remove[:-1]]) # prevent if first is True\n",
        "    indices_to_remove = sorted_logits_index[sorted_indices_to_remove]\n",
        "\n",
        "    logits[indices_to_remove]=filter_value\n",
        "\n",
        "  return logits   # logits = (vocab_size, )\n"
      ],
      "metadata": {
        "id": "Y3gxMcb8OxxL"
      },
      "execution_count": 193,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Greedy & Generate_sentence Function"
      ],
      "metadata": {
        "id": "-c0qYyVEqaoU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_sent(seed_word,model,max_len=100,greedy=False,top_k=0,top_p=0.0):\n",
        "  sent= seed_word\n",
        "  toked = sp.encode(sent)\n",
        "\n",
        "  for _ in range(max_len):\n",
        "    input_ids = torch.LongTensor([sp.bos_id()]+toked)[None,:] # input_ids = (1, cumulated_seq_len)\n",
        "    outputs = model(input_ids)[0,-1,:] # outputs : (vocab_size, )\n",
        "\n",
        "    if greedy:\n",
        "      gen = sp.id_to_piece(outputs.argmax().tolist()) # outputs.argmax().tolist() -> int\n",
        "    else:\n",
        "      output_logits = top_k_top_p_filtering(outputs,top_k,top_p) # logits = (vocab_size, )\n",
        "      gen = torch.multinomial(nn.Softmax(-1)(output_logits),num_samples=1,replacement=True).tolist()[0]\n",
        "      gen = sp.id_to_piece(gen)\n",
        "    if gen == '</s>':\n",
        "      break\n",
        "\n",
        "    sent+=gen.replace('▁',' ')\n",
        "    toked=sp.encode(sent)\n",
        "\n",
        "  return sent"
      ],
      "metadata": {
        "id": "7FD4jcD3eLBS"
      },
      "execution_count": 244,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Huggingface Transformers"
      ],
      "metadata": {
        "id": "2tF56U0HqZSs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Au-SM5_crBt4",
        "outputId": "12c89097-e469-46eb-ad1e-8cb417e8a853"
      },
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "config.json  kor_tokenizer.model  model.safetensors\n",
            "corpus.txt   kor_tokenizer.vocab\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers"
      ],
      "metadata": {
        "id": "uG_2d-qWo3Nq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2LMHeadModel"
      ],
      "metadata": {
        "id": "oVRNhprurFxi"
      },
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model"
      ],
      "metadata": {
        "id": "4JZU6PS-rdS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TK5seQ5Qr8eI",
        "outputId": "4ee21250-3f4f-4f42-fd63-a5d747c6fd69"
      },
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Pytorch NLP/GPT-2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GPT2Gen(nn.Module):\n",
        "  def __init__(self,dir_path):\n",
        "    super(GPT2Gen,self).__init__()\n",
        "    self.gpt2 = GPT2LMHeadModel.from_pretrained(dir_path,ignore_mismatched_sizes=True)\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.gpt2(x)[0] # (batch_size=1, cumulated_seq_len, vocab_size =500000)"
      ],
      "metadata": {
        "id": "O-FSehzxrOCz"
      },
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpt2_model = GPT2Gen('./data_in/gpt2_ckpt')"
      ],
      "metadata": {
        "id": "5H6yvm_Jsdw3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate_sentences"
      ],
      "metadata": {
        "id": "slaZ1EEntEWj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generate_sent('안녕',gpt2_model,top_k=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "TK_KLic3tB6P",
        "outputId": "a5428767-a406-4e84-a858-f17fab9cc48e"
      },
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-195-c286d1860d07>:13: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  gen = torch.multinomial(nn.Softmax()(output_logits),num_samples=1,replacement=True).tolist()[0]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'안녕 행복하길 바쁘노릇실상 귀여트랑실상 협주곡실상실상 협주곡 귀여태격태격태격 행복하길 있었는지 귀여실상실상 귀여 협주곡 무료영화 니가 귀여실상 귀여트랑 무료영화트랑트랑태격 귀여실상실상 귀여딩딩태격 니가 협주곡트랑태격태격실상 무료영화실상실상실상실상트랑 협주곡실상 바쁘 니가 가고싶실상실상실상 바쁘트랑태격 협주곡실상실상 기대되네요트랑실상실상 협주곡실상실상실상실상실상실상높음 협주곡실상 가고싶 바쁘 단어에실상트랑실상 단어에 짜맞추 협주곡실상 단어에트랑트랑 협주곡 협주곡 바쁘트랑트랑 짜맞추실상 바쁘'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 196
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mxImBf-LtQwz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}