{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DonghaeSuh/NLP_Pytorch/blob/main/Model/Transformer_Chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obEMtyAfmfoi"
      },
      "source": [
        "# 데이터 마련"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7jIeCkmuXFPr"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "niwCvt_km_5z",
        "outputId": "6221632c-8ab6-4ccf-fb2b-0533c312ea9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ],
      "source": [
        "ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IA-ZkQhknBMa",
        "outputId": "e46cce39-dca0-4217-bde9-b4c9ce3819a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Pytorch NLP/data_in/Chatbot\n"
          ]
        }
      ],
      "source": [
        "cd drive/MyDrive/Pytorch\\ NLP/data_in/Chatbot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEXE23tmnCo6",
        "outputId": "42c78abb-95bf-4fe0-8aa5-84ffbfa1a936"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2_Fine_ChatbotData.csv  ChatbotData.csv       \u001b[0m\u001b[01;34mMecab-ko-for-Google-Colab\u001b[0m/\n",
            "\u001b[01;34mbest_weight\u001b[0m/            Fine_ChatbotData.csv  vocab_word.csv\n"
          ]
        }
      ],
      "source": [
        "ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "7Ti-xyO3nGP6"
      },
      "outputs": [],
      "source": [
        "vocab_word=pd.read_csv('vocab_word.csv')\n",
        "train_data=pd.read_csv('2_Fine_ChatbotData.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ioEj60fJnRfj"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 2\n",
        "MAX_LEN = 25\n",
        "EPOCHS = 30\n",
        "NUM_LAYERS = 2\n",
        "FEED_WORWARD_DIM=2048"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIwio5umoM8o",
        "outputId": "4b5cefab-e8e2-43e1-bf2f-abed2c07bfcf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchtext==0.6\n",
            "  Downloading torchtext-0.6.0-py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6) (4.65.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6) (2.27.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6) (2.0.1+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6) (1.22.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6) (1.16.0)\n",
            "Collecting sentencepiece (from torchtext==0.6)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6) (3.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->torchtext==0.6) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->torchtext==0.6) (16.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torchtext==0.6) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torchtext==0.6) (1.3.0)\n",
            "Installing collected packages: sentencepiece, torchtext\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.15.2\n",
            "    Uninstalling torchtext-0.15.2:\n",
            "      Successfully uninstalled torchtext-0.15.2\n",
            "Successfully installed sentencepiece-0.1.99 torchtext-0.6.0\n"
          ]
        }
      ],
      "source": [
        "pip install torchtext==0.6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "_Sb6ZxGNoO6P"
      },
      "outputs": [],
      "source": [
        "from torchtext import data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "zVrBU9qnoUbR"
      },
      "outputs": [],
      "source": [
        "# vocab 전용\n",
        "V=data.Field(sequential=True,\n",
        "             use_vocab=True,\n",
        "             tokenize=str.split,\n",
        "             init_token='<sos>',\n",
        "             eos_token='<eos>',\n",
        "             fix_length=MAX_LEN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "-kS_NOZMoZ-C"
      },
      "outputs": [],
      "source": [
        "Q=data.Field(sequential=True,\n",
        "             use_vocab=True,\n",
        "             tokenize=str.split,\n",
        "             batch_first=True,\n",
        "             fix_length=MAX_LEN)\n",
        "\n",
        "A=data.Field(sequential=True,\n",
        "             use_vocab=True,\n",
        "             init_token='<sos>',\n",
        "             eos_token='<eos>',\n",
        "             tokenize=str.split,\n",
        "             batch_first=True,\n",
        "             fix_length=MAX_LEN)\n",
        "LABEL=data.Field(sequential=True,\n",
        "                 use_vocab=True,\n",
        "                 eos_token='<eos>',\n",
        "                 tokenize=str.split,\n",
        "                 batch_first=True,\n",
        "                 fix_length=MAX_LEN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "rx6NPj3KoblJ"
      },
      "outputs": [],
      "source": [
        "from torchtext.data import TabularDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvy11Aq4oe5x",
        "outputId": "537c928f-a538-4349-84cb-6bfbb2a9a20b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'question': ['12시', '땡'],\n",
              " 'answer': ['하루가', '또', '가네요'],\n",
              " 'label': ['하루가', '또', '가네요']}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "train_data=TabularDataset('2_Fine_ChatbotData.csv',format='csv',fields=[('question',Q),('answer',A),('label',LABEL)],skip_header=True)\n",
        "vars(train_data[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "mHbljGn_oeWJ"
      },
      "outputs": [],
      "source": [
        "vocab_data=TabularDataset('vocab_word.csv',format='csv',fields=[('vocab_word',V)],skip_header=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "DFCBMdmyolxP"
      },
      "outputs": [],
      "source": [
        "V.build_vocab(vocab_data,min_freq=2)\n",
        "\n",
        "Q.vocab=V.vocab\n",
        "A.vocab=V.vocab\n",
        "LABEL.vocab=V.vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "MWAVwXCvopEV"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import torch\n",
        "SEED=123\n",
        "random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "train_data,val_data=train_data.split(split_ratio=0.9,random_state=random.seed(SEED))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "72QK0boQoqmY"
      },
      "outputs": [],
      "source": [
        "from torchtext.data import Iterator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "IekjCN8Rorz2"
      },
      "outputs": [],
      "source": [
        "train_iter=Iterator(train_data,batch_size=BATCH_SIZE)\n",
        "val_iter=Iterator(val_data,batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KSIEl3oCotMB",
        "outputId": "eee34fa8-a9fa-47f8-bb68-ceb640ebc6aa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 742,  202, 1854, 5302,  211,    1,    1,    1,    1,    1,    1,    1,\n",
              "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "            1],\n",
              "        [  45,    0,    0, 2612,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "            1]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "batch=next(iter(train_iter))\n",
        "batch.question"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FABPp1jYoupe",
        "outputId": "352071b6-5bdb-47d2-fd4d-c4e01a5a0c9d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[   2, 4448, 4528, 3233,  858,  321, 4934,   89,    3,    1,    1,    1,\n",
              "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "            1],\n",
              "        [   2,  978, 1768,  539,   89,    3,    1,    1,    1,    1,    1,    1,\n",
              "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "            1]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "batch.answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAjiNjlCoxM5",
        "outputId": "8e2db1b7-649d-46af-c3de-f31af4f35c23"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[4448, 4528, 3233,  858,  321, 4934,   89,    3,    1,    1,    1,    1,\n",
              "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "            1],\n",
              "        [ 978, 1768,  539,   89,    3,    1,    1,    1,    1,    1,    1,    1,\n",
              "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "            1]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "batch.label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "kwp-7ekIo1hj"
      },
      "outputs": [],
      "source": [
        "train_iter=Iterator(train_data,batch_size=BATCH_SIZE)\n",
        "val_iter=Iterator(val_data,batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-zffnATo_TB"
      },
      "source": [
        "# 모델 구현"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "1KXCz0llpASK"
      },
      "outputs": [],
      "source": [
        "## hyperparameter\n",
        "BATCH_SIZE=2\n",
        "EPOCH=30\n",
        "MAX_LEN=25\n",
        "kargs={'max_len':MAX_LEN,\n",
        "       'emb_dim':512,\n",
        "       'd_model':512,\n",
        "       'num_layers':2,\n",
        "       'num_heads':8,\n",
        "       'ffn_dim':2048,\n",
        "       'vocab_size':len(V.vocab),\n",
        "       'p_rate':0.1\n",
        "       }\n",
        "\n",
        "device='cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "SIopOeY9sPDf"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJ46b7EX_9-C"
      },
      "source": [
        "### positional_encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "tsZuI8rEH5ua"
      },
      "outputs": [],
      "source": [
        "def positional_encoding(pos,d_model):\n",
        "  pos=torch.arange(pos).unsqueeze(-1).to(device)\n",
        "  i=torch.arange(d_model).unsqueeze(0).to(device)\n",
        "\n",
        "  angle=pos/(torch.pow(10000,(2*i/d_model)))\n",
        "\n",
        "  angle[:,0::2]=torch.sin(angle[:,0::2])\n",
        "  angle[:,1::2]=torch.cos(angle[:,1::2])\n",
        "\n",
        "  PE=angle.unsqueeze(0) # PE : ( 1, max_len, d_model )\n",
        "  \n",
        "  return PE # PE : ( 1, max_len, d_model )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vOrVe4H62MlY"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0SkKYWqa45UO"
      },
      "outputs": [],
      "source": [
        "pe=positional_encoding(25,512)\n",
        "\n",
        "plt.pcolormesh(pe[0],cmap='RdBu')\n",
        "plt.xlabel('emb_dim')\n",
        "plt.ylabel('max_len')\n",
        "plt.colorbar()\n",
        "plt.show"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dni9UQeR_s9A"
      },
      "source": [
        "### 테스트"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5hIS5q7BywIl"
      },
      "outputs": [],
      "source": [
        "a=torch.arange(5).unsqueeze(dim=-1) # position\n",
        "b=torch.arange(10).unsqueeze(dim=0)\n",
        "print(a)\n",
        "print(b)\n",
        "a*b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfXgHEN3odT4",
        "outputId": "06a86cef-ad2d-465e-b377-e86f86087258"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-0.0000e+00, -0.0000e+00, -1.0000e+09],\n",
              "        [-0.0000e+00, -1.0000e+09, -1.0000e+09]])"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a=torch.Tensor([[2,3,1],[4,1,1]])\n",
        "mask=torch.ones(a.size())\n",
        "mask=(a==mask)*-1e9\n",
        "mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UD90tDq2tYrm",
        "outputId": "b8bcdc76-88c1-49c3-910c-0620ea0dfb20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[[-0.0000e+00, -0.0000e+00, -1.0000e+09]]],\n",
            "\n",
            "\n",
            "        [[[-0.0000e+00, -1.0000e+09, -1.0000e+09]]]]) torch.Size([2, 1, 1, 3])\n"
          ]
        }
      ],
      "source": [
        "print(mask[:,None,None,:],mask[:,None,None,:].size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-XC3CzNs30t",
        "outputId": "2f96a9bf-7d63-4ce0-a156-ab085014a694"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[0., 1., 2.],\n",
              "         [3., 4., 5.]],\n",
              "\n",
              "        [[4., 3., 2.],\n",
              "         [7., 6., 5.]]])"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a=torch.Tensor([[[1,2,3],[4,5,6]],[[3,2,1],[6,5,4]]])\n",
        "b=torch.Tensor([[[-1,-1,-1]],[[1,1,1]]])\n",
        "a+b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8hg3iADt59vl",
        "outputId": "98352aa1-7f0a-4bf9-fb85-c1a6ca9328f0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0., 1., 1.])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a=torch.Tensor([False,True,True])\n",
        "b=torch.Tensor([False,False,True])\n",
        "torch.maximum(a,b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-m8Vkse_xU6"
      },
      "source": [
        "### padding mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "nxtzEXF3nWmQ"
      },
      "outputs": [],
      "source": [
        "def padding_mask(inp):\n",
        "  # inp : ( batch_size, max_len ) \n",
        "  # padding mask\n",
        "  mask=torch.ones(inp.size()).to(device)  # ( batch_size, max_len ) \n",
        "  mask=(inp==mask)*-1e9  # ( batch_size, max_len ) \n",
        "  padding_mask=mask[:,None,None,:] # ( batch_size, 1, 1, max_len )\n",
        "  \n",
        "  return padding_mask # ( batch_size, 1, 1, max_len )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "padding_mask(torch.Tensor([[4,2,3,4,1,1]]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsb7dFYUAcyk",
        "outputId": "1d28af3e-8700-471f-cd98-66aa4b2dc4f2"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[-0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -1.0000e+09,\n",
              "           -1.0000e+09]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPsgVrZh_0U5"
      },
      "source": [
        "### 테스트"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQYqikBv8T2K",
        "outputId": "2e5eaa74-063f-4bc7-cf60-8530b8825a21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1., 1., 1., 1.],\n",
            "        [0., 1., 1., 1.],\n",
            "        [0., 0., 1., 1.],\n",
            "        [0., 0., 0., 1.]])\n",
            "tensor([[0., 1., 1., 1.],\n",
            "        [0., 0., 1., 1.],\n",
            "        [0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0.]])\n",
            "tensor([[1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [0., 1., 1., 1.],\n",
            "        [0., 0., 1., 1.]])\n",
            "torch.Size([2, 1, 4, 4])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([[[[0., 1., 1., 1.],\n",
              "          [0., 0., 1., 1.],\n",
              "          [0., 0., 0., 1.],\n",
              "          [0., 0., 0., 0.]]],\n",
              "\n",
              "\n",
              "        [[[0., 1., 1., 1.],\n",
              "          [0., 0., 1., 1.],\n",
              "          [0., 0., 0., 1.],\n",
              "          [0., 0., 0., 0.]]]])"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a=torch.ones(4,4)\n",
        "print(a.triu(diagonal=0))\n",
        "print(a.triu(diagonal=1)) # 이게 필요\n",
        "print(a.triu(diagonal=-1))\n",
        "c=a.triu(diagonal=1)\n",
        "print(c.repeat(2,1,1,1).size())\n",
        "c.repeat(2,1,1,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3P_L8ACC_Woo",
        "outputId": "fec17193-dc0f-4c76-c153-b2eb04284485"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0., 1., 1., 1.],\n",
              "        [0., 0., 1., 1.],\n",
              "        [0., 0., 1., 1.],\n",
              "        [0., 0., 1., 1.]])"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a=a.triu(diagonal=1)\n",
        "b=torch.Tensor([[0,0,1,1]])\n",
        "torch.maximum(a,b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxCDHjdUAKYx",
        "outputId": "d2d43977-cc6e-4087-8b5d-73092964ab25"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[[-0.0000e+00, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
              "          [-0.0000e+00, -0.0000e+00, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
              "          [-0.0000e+00, -0.0000e+00, -0.0000e+00, -1.0000e+09, -1.0000e+09],\n",
              "          [-0.0000e+00, -0.0000e+00, -0.0000e+00, -1.0000e+09, -1.0000e+09],\n",
              "          [-0.0000e+00, -0.0000e+00, -0.0000e+00, -1.0000e+09, -1.0000e+09]]],\n",
              "\n",
              "\n",
              "        [[[-1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
              "          [-1.0000e+09, -0.0000e+00, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
              "          [-1.0000e+09, -0.0000e+00, -0.0000e+00, -1.0000e+09, -1.0000e+09],\n",
              "          [-1.0000e+09, -0.0000e+00, -0.0000e+00, -0.0000e+00, -1.0000e+09],\n",
              "          [-1.0000e+09, -0.0000e+00, -0.0000e+00, -0.0000e+00, -1.0000e+09]]]])"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "look_ahead_mask(torch.Tensor([[4,2,3,1,1],[1,2,3,2,1]]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTX_AqwR_2cJ"
      },
      "source": [
        "### look_ahead_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "6gK51SBast2M"
      },
      "outputs": [],
      "source": [
        "def look_ahead_mask(tar):\n",
        "  # tar : ( batch_size, max_len )\n",
        "\n",
        "  # padding mask (padding 부분이 True,  아닌 부분이 False인 요소로 채워진 Tensor)\n",
        "  mask=torch.ones(tar.size()).to(device)  # ( batch_size, max_len ) \n",
        "\n",
        "  padding_mask=(tar==mask)  # ( batch_size, max_len ) \n",
        "  padding_mask=padding_mask[:,None,None,:] # ( batch_size, 1, 1, max_len )\n",
        "\n",
        "  # look_ahead mask\n",
        "  ones=torch.ones(tar.size()[1],tar.size()[1]).to(device) # ( max_len, max_len )\n",
        "  look_ahead_mask=ones.triu(diagonal=1).to(device) # ( max_len, max_len )\n",
        "  look_ahead_mask=look_ahead_mask.repeat(tar.size()[0],1,1,1) # ( batch_size, 1, ,max_len, max_len )\n",
        "\n",
        "  look_ahead_mask=torch.maximum(padding_mask,look_ahead_mask)*-1e9\n",
        "  \n",
        "  return look_ahead_mask # ( batch_size, 1, ,max_len, max_len )"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Xj1yJJ4U_jwB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m946s_wt6xdd"
      },
      "source": [
        "### 테스트"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "a70r7WG45k74",
        "outputId": "0483970a-77b8-475b-f31e-a43e6d2ed9aa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f52b94b9570>"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 480x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.matshow(look_ahead_mask(batch.answer)[0][0]) # 이를 표현할 때에는 .to(device)를 모두 제거해야 한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "gaI4LotA6UEe",
        "outputId": "e057b02d-1e3c-418c-df66-f32cf6e440e7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f52b8a217b0>"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 480x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.matshow(look_ahead_mask(batch.answer)[1][0]) # 이를 표현할 때에는 .to(device)를 모두 제거해야 한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWEfMRuPDFL4"
      },
      "source": [
        "### Multi-head Attention\n",
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "D9AbpitsN1HR"
      },
      "outputs": [],
      "source": [
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "1OWfynWhJtxC"
      },
      "outputs": [],
      "source": [
        "class MultiheadAttention(nn.Module):\n",
        "  def __init__(self,**kargs):\n",
        "    super(MultiheadAttention,self).__init__()\n",
        "\n",
        "    self.num_head=kargs['num_heads']\n",
        "    self.d_model=kargs['emb_dim']\n",
        "    self.depth=int(self.d_model/self.num_head)  # d_model%num_head=0\n",
        "\n",
        "    self.wq=nn.Linear(kargs['d_model'],kargs['d_model'])\n",
        "    self.wk=nn.Linear(kargs['d_model'],kargs['d_model'])\n",
        "    self.wv=nn.Linear(kargs['d_model'],kargs['d_model'])\n",
        "\n",
        "    self.final_Linear=nn.Linear(kargs['d_model'],kargs['d_model'])\n",
        "\n",
        "    self.softmax=nn.Softmax(dim=-1)\n",
        "\n",
        "  def split_head(self,x): # x : ( batch_size, max_len, emb_dim )\n",
        "    x = x.reshape( x.size()[0] , -1, self.num_head , self.depth ) \n",
        "    # ( batch_size, max_len, num_head, depth ) # num_head*depth=emb_dim\n",
        "\n",
        "    return x.permute(0,2,1,3) # ( batch_size, num_head, max_len, depth )\n",
        "\n",
        "  def forward(self,q,k,v,mask):\n",
        "    # q,k,v = ( batch_size, max_len, emb_dim )\n",
        "    # mask = ( batch_size, 1, 1, max_len ) or ( batch_size, 1, max_len, max_len )\n",
        "\n",
        "    q = self.wq(q) # ( batch_size, max_len, emb_dim )\n",
        "    k = self.wk(k) # ( batch_size, max_len, emb_dim )\n",
        "    v = self.wv(v) # ( batch_size, max_len, emb_dim )\n",
        "\n",
        "    root_dk=math.sqrt(k.size()[-1]) \n",
        "\n",
        "    # split by head\n",
        "    q=self.split_head(q) # ( batch_size, num_head, max_len, depth )\n",
        "    k=self.split_head(k) # ( batch_size, num_head, max_len, depth )\n",
        "    v=self.split_head(v) # ( batch_size, num_head, max_len, depth )\n",
        "\n",
        "    # scaled Dot-Product Attention\n",
        "    score=torch.matmul(q, k.transpose(2,3))/root_dk # ( batch_size, num_haed, max_len, max_len )\n",
        "    masked_score = score+mask # ( batch_size, num_haed, max_len, max_len )\n",
        "    attention = torch.matmul(self.softmax(masked_score), v ) # ( batch_size, num_haed, max_len, depth )\n",
        "\n",
        "    # Concat and Linear\n",
        "    pre_permute = attention.permute(0,2,1,3) # ( batch_size, max_len, num_head, depth )\n",
        "    z = pre_permute.reshape(pre_permute.size()[0],-1,self.d_model) # ( batch_size, max_len, emb_dim )\n",
        "    z = self.final_Linear(z)\n",
        "\n",
        "    return z, attention # ( batch_size, max_len, emb_dim )  <= q,k,v of next Encoder / attetion weigth : ( batch_size, num_haed, max_len, depth )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NU8Gw5LxDET5"
      },
      "source": [
        "### 테스트"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hlXy366DJLJ",
        "outputId": "bce7c844-b3dc-4b2b-d800-5ae508da9ab6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[ 1.,  2.,  3.,  4.],\n",
            "         [ 4.,  5.,  6.,  7.]],\n",
            "\n",
            "        [[ 7.,  8.,  9., 10.],\n",
            "         [10., 11., 12., 13.]]])\n",
            "torch.Size([2, 2, 4])\n",
            "tensor([[[[ 1.,  2.],\n",
            "          [ 3.,  4.]],\n",
            "\n",
            "         [[ 4.,  5.],\n",
            "          [ 6.,  7.]]],\n",
            "\n",
            "\n",
            "        [[[ 7.,  8.],\n",
            "          [ 9., 10.]],\n",
            "\n",
            "         [[10., 11.],\n",
            "          [12., 13.]]]])\n",
            "torch.Size([2, 2, 2, 2])\n",
            "tensor([[[[ 1.,  2.],\n",
            "          [ 4.,  5.]],\n",
            "\n",
            "         [[ 3.,  4.],\n",
            "          [ 6.,  7.]]],\n",
            "\n",
            "\n",
            "        [[[ 7.,  8.],\n",
            "          [10., 11.]],\n",
            "\n",
            "         [[ 9., 10.],\n",
            "          [12., 13.]]]])\n",
            "torch.Size([2, 2, 2, 2])\n"
          ]
        }
      ],
      "source": [
        "a=torch.Tensor([[[1,2,3,4],[4,5,6,7]],[[7,8,9,10],[10,11,12,13]]])\n",
        "print(a,a.size(),sep='\\n')\n",
        "b=a.view(2,-1,2,2)\n",
        "print(b,b.size(),sep='\\n')\n",
        "c=b.permute(0,2,1,3)\n",
        "print(c,c.size(),sep='\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XwnLGD4_675M",
        "outputId": "ff25ad6b-96bf-4ca2-efa8-c4db7d2b972d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[[ 1.,  2.],\n",
            "          [ 3.,  4.]],\n",
            "\n",
            "         [[ 4.,  5.],\n",
            "          [ 6.,  7.]]],\n",
            "\n",
            "\n",
            "        [[[ 7.,  8.],\n",
            "          [ 9., 10.]],\n",
            "\n",
            "         [[10., 11.],\n",
            "          [12., 13.]]]])\n",
            "torch.Size([2, 2, 2, 2])\n",
            "tensor([[[ 1.,  2.,  3.,  4.],\n",
            "         [ 4.,  5.,  6.,  7.]],\n",
            "\n",
            "        [[ 7.,  8.,  9., 10.],\n",
            "         [10., 11., 12., 13.]]])\n",
            "torch.Size([2, 2, 4])\n"
          ]
        }
      ],
      "source": [
        "d=c.permute(0,2,1,3)\n",
        "print(d,d.size(),sep='\\n')\n",
        "e=d.view(d.size()[0],-1,4)\n",
        "print(e,e.size(),sep='\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCvZiGf6OLIK",
        "outputId": "c99c8aa6-dfa6-42d3-dfb8-3ff6713b01b5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[[0.1000, 0.4000],\n",
              "          [0.2000, 0.5000]],\n",
              "\n",
              "         [[0.3000, 0.6000],\n",
              "          [0.4000, 0.7000]]],\n",
              "\n",
              "\n",
              "        [[[0.7000, 1.0000],\n",
              "          [0.8000, 1.1000]],\n",
              "\n",
              "         [[0.9000, 1.2000],\n",
              "          [1.0000, 1.3000]]]])"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "c.transpose(2,3)/10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpmWX7s5_QPG"
      },
      "source": [
        "### Feed Forward Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "zNTZnLAT_PkX"
      },
      "outputs": [],
      "source": [
        "def FeedForward(**kargs):\n",
        "    return nn.Sequential(nn.Linear(kargs['d_model'],kargs['ffn_dim']),\n",
        "                         nn.ReLU(),\n",
        "                         nn.Linear(kargs['ffn_dim'],kargs['d_model'])).to(device) # ( batch_size, max_len, emb_dim )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-72XPENJi13"
      },
      "source": [
        "## Encoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8W9Fy0OE70h3"
      },
      "source": [
        "### Encoder Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "1sCt7xvdsku0"
      },
      "outputs": [],
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "  def __init__(self,**kargs):\n",
        "    super(EncoderLayer,self).__init__()\n",
        "\n",
        "    self.mha=MultiheadAttention(**kargs).to(device)\n",
        "    self.ffn=FeedForward(**kargs)\n",
        "\n",
        "    self.Norm1=nn.LayerNorm(kargs['d_model'],eps=1e-6)\n",
        "    self.Norm2=nn.LayerNorm(kargs['d_model'],eps=1e-6)\n",
        "\n",
        "    self.dropout1=nn.Dropout(kargs['p_rate'])\n",
        "    self.dropout2=nn.Dropout(kargs['p_rate'])\n",
        "\n",
        "  def forward(self,x,mask):\n",
        "    # x = ( batch_size, max_len, emb_dim )\n",
        "    # mask = ( batch_size, 1, 1, max_len ) or ( batch_size, 1, max_len, max_len )\n",
        "\n",
        "    # multi-head attention  # ( batch_size, max_len, emb_dim )\n",
        "    post_mha,_=self.mha(x,x,x,mask) \n",
        "    post_mha=self.dropout1(post_mha)\n",
        "    post_add_norm=self.Norm1(x+post_mha) # Add&Norm  # ( batch_size, max_len, emb_dim )\n",
        "\n",
        "    # feed forward network\n",
        "    post_ffn = self.ffn(post_add_norm) # ( batch_size, max_len, emb_dim )\n",
        "    post_ffn = self.dropout2(post_ffn)\n",
        "    output = self.Norm2(post_add_norm+post_ffn) # ( batch_size, max_len, emb_dim )\n",
        "    \n",
        "    return output # ( batch_size, max_len, emb_dim ) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3Qyxh8rJWe1"
      },
      "source": [
        "### Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "4quNkMUmsQ4X"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self,**kargs):\n",
        "    super(Encoder,self).__init__()\n",
        "    self.embedding=nn.Embedding(kargs['vocab_size'],kargs['emb_dim'])\n",
        "    self.pe=positional_encoding(kargs['max_len'],kargs['emb_dim']) # PE : ( 1, max_len, d_model )\n",
        "    self.dropout=nn.Dropout(kargs['p_rate'])\n",
        "\n",
        "    self.enc_layer=[ EncoderLayer(**kargs).to(device) for _ in range(kargs['num_layers']) ]\n",
        "\n",
        "  def forward(self,inp,mask):\n",
        "      # inp = ( batch_size, max_len )\n",
        "      # mask = ( batch_size, 1, 1, max_len ) or ( batch_size, 1, max_len, max_len )\n",
        "      post_emb = self.embedding(inp) # ( batch_size, max_len, emb_dim )\n",
        "      post_emb*=math.sqrt(kargs['d_model'])\n",
        "      x=post_emb+self.pe # ( batch_size, max_len, emb_dim )\n",
        "\n",
        "      for i in range(kargs['num_layers']):\n",
        "        x= self.enc_layer[i](x,mask)  # ( batch_size, max_len, emb_dim )\n",
        "\n",
        "      return x # ( batch_size, max_len, emb_dim )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBZZA-ymJbvE"
      },
      "source": [
        "## Decoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kyusPH_7Zds"
      },
      "source": [
        "### DecoderLayer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "nky4RGjjMzJl"
      },
      "outputs": [],
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "  def __init__(self,**kargs):\n",
        "    super(DecoderLayer,self).__init__()\n",
        "    self.m_mha = MultiheadAttention(**kargs)\n",
        "    self.mha = MultiheadAttention(**kargs)\n",
        "\n",
        "    self.ffn = FeedForward(**kargs)\n",
        "\n",
        "    self.Norm1 = nn.LayerNorm(kargs['d_model'],eps=1e-6)\n",
        "    self.Norm2 = nn.LayerNorm(kargs['d_model'],eps=1e-6)\n",
        "    self.Norm3 = nn.LayerNorm(kargs['d_model'],eps=1e-6)\n",
        "\n",
        "    self.dropout1 = nn.Dropout(kargs['p_rate'])\n",
        "    self.dropout2 = nn.Dropout(kargs['p_rate'])\n",
        "    self.dropout3 = nn.Dropout(kargs['p_rate'])\n",
        "\n",
        "  def forward(self,dec_input, enc_output, look_ahead_mask,padding_mask):\n",
        "    # x : ( batch_size, max_len, emb_dim )\n",
        "    # look_ahead_mask : ( batch_size, 1, max_len, max_len )\n",
        "    # padding_mask : ( batch_size, 1, 1, max_len )\n",
        "\n",
        "    # masked_multi-head attention\n",
        "    post_m_mha, attention_weight_block1= self.m_mha(dec_input, dec_input, dec_input, look_ahead_mask) \n",
        "    # ( batch_size, max_len, emb_dim ) / attetion weigth : ( batch_size, num_haed, max_len, depth )\n",
        "    post_m_mha = self.dropout1(post_m_mha) # ( batch_size, max_len, emb_dim )\n",
        "    out1= self.Norm1(dec_input+post_m_mha) # ( batch_size, max_len, emb_dim )\n",
        "\n",
        "    # multi-haed attetnion\n",
        "    post_mha, attention_weight_block2 = self.mha(out1, enc_output, enc_output, padding_mask )  \n",
        "    # ( batch_size, max_len, emb_dim ) / attetion weigth : ( batch_size, num_haed, max_len, depth )\n",
        "    post_mha = self.dropout2(post_mha)  # ( batch_size, max_len, emb_dim )\n",
        "    out2 = self.Norm2(out1+post_mha)  # ( batch_size, max_len, emb_dim )\n",
        "\n",
        "    # feed forward network\n",
        "    post_ffn = self.ffn(out2) # ( batch_size, max_len, emb_dim )\n",
        "    out3 = self.Norm3(out2+post_ffn) # ( batch_size, max_len, emb_dim )\n",
        "\n",
        "    return out3 , attention_weight_block1, attention_weight_block2 \n",
        "    # ( batch_size, max_len, emb_dim ) / attetion weigth : ( batch_size, num_haed, max_len, depth )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4x_SoKTH7ay7"
      },
      "source": [
        "### Decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "Djd8KXG_P3sI"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "  def __init__(self,**kargs):\n",
        "    super(Decoder,self).__init__()\n",
        "    \n",
        "    self.embedding = nn.Embedding(kargs['vocab_size'],kargs['emb_dim'])\n",
        "    self.pe = positional_encoding(kargs['max_len'],kargs['d_model'])\n",
        "\n",
        "    self.dec_layer = [DecoderLayer(**kargs).to(device) for _ in range(kargs['num_layers'])]\n",
        "\n",
        "    self.dropout = nn.Dropout(kargs['p_rate'])\n",
        "\n",
        "  def forward(self,dec_input, enc_output, look_ahead_mask, padding_mask ):\n",
        "    # dec_input : ( batch_size, max_len, emb_dim )\n",
        "    # enc_output : ( batch_size, max_len, emb_dim )\n",
        "    # look_ahead_mask : ( batch_size, 1, max_len, max_len )\n",
        "    # padding_mask : ( batch_size, 1, 1, max_len )\n",
        "\n",
        "    attention_weights = {}\n",
        "    seq_len = dec_input.size()[1]\n",
        "\n",
        "    post_emb = self.embedding(dec_input) # ( batch_size, max_len, emb_dim )\n",
        "    post_emb*=math.sqrt(kargs['d_model']) # scaling , ( batch_size, max_len, emb_dim )\n",
        "    post_emb+=self.pe[:,:seq_len, :] # ( batch_size, max_len, emb_dim )\n",
        "    output = self.dropout(post_emb) # ( batch_size, max_len, emb_dim )\n",
        "\n",
        "\n",
        "    for i in range(kargs['num_layers']):\n",
        "      output, block1, block2 = self.dec_layer[i](output, enc_output, look_ahead_mask, padding_mask) \n",
        "      # ( batch_size, max_len, emb_dim ) / attetion weigth_block : ( batch_size, num_haed, max_len, depth )\n",
        "      attention_weights['decoder_layer{}_block1'.format(i+1)]=block1\n",
        "      attention_weights['decoder_layer{}_block2'.format(i+1)]=block2\n",
        "\n",
        "    return output, attention_weights\n",
        "    # ( batch_size, max_len, emb_dim )\n",
        "    # attention_weights : 각 layer의 mha block의 attention 가중치가 value로 담겨있는 사전"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWzdEa3F7TfD"
      },
      "source": [
        "## Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "hzwZONlZ3AD6"
      },
      "outputs": [],
      "source": [
        "class Transformer(nn.Module):\n",
        "  def __init__(self,**kargs):\n",
        "    super(Transformer,self).__init__()\n",
        "    self.encoder = Encoder(**kargs)\n",
        "    self.decoder = Decoder(**kargs)\n",
        "\n",
        "    self.final_Linear = nn.Linear(kargs['emb_dim'],kargs['vocab_size'])\n",
        "\n",
        "  def forward(self,inp,tar):\n",
        "    # inp : ( batch_size, max_len )\n",
        "    # tar : ( batch_size, max_len )\n",
        "    # look_ahead_mask : ( batch_size, 1, max_len, max_len )\n",
        "    # padding_mask : ( batch_size, 1, 1, max_len )\n",
        "\n",
        "    # create mask\n",
        "    inp_mask = padding_mask(inp) # padding_mask : ( batch_size, 1, 1, max_len )\n",
        "    tar_mask1 = look_ahead_mask(tar)  # look_ahead_mask : ( batch_size, 1, max_len, max_len )\n",
        "    tar_mask2 = padding_mask(tar) # padding_mask : ( batch_size, 1, 1, max_len )\n",
        "\n",
        "    # encoder\n",
        "    enc_output = self.encoder(inp,inp_mask) # ( batch_size, max_len, emb_dim )\n",
        "\n",
        "    # decoder\n",
        "    dec_output,_ = self.decoder(tar, enc_output, tar_mask1, tar_mask2) # ( batch_size, max_len, emb_dim )\n",
        "    \n",
        "    # Linear\n",
        "    output = self.final_Linear(dec_output) # ( batch_size, max_len, vocab_size )\n",
        "    output = output.transpose(1,2) # ( batch_size, vocab_size, max_len )\n",
        "\n",
        "    return output # ( batch_size, vocab_size, max_len )\n",
        "\n",
        "  def inference(self,inp,max_ans_len):\n",
        "    # inp : ( 1, max_len )\n",
        "    inp_mask = padding_mask(inp) # padding_mask : ( 1, 1, 1, max_len )\n",
        "    enc_output = self.encoder(inp,inp_mask) # ( 1, max_len, emb_size )\n",
        "\n",
        "    tar=[[V.vocab.stoi['<sos>']]+[V.vocab.stoi['<pad>']]*(kargs['max_len']-1)]\n",
        "    tar = torch.LongTensor(tar).to(device) # ( 1, max_len )\n",
        "\n",
        "    predict=list()\n",
        "\n",
        "    for t in range(max_ans_len):\n",
        "      tar_mask1 = look_ahead_mask(tar)  # look_ahead_mask : ( 1, 1, 25, 25 )\n",
        "      tar_mask2 = padding_mask(tar) # padding_mask : ( 1, 1, 1, 25 )\n",
        "      dec_output,_ = self.decoder(tar,enc_output,tar_mask1,tar_mask2) # ( 1, 25, emb_dim )\n",
        "      output = self.final_Linear(dec_output) # ( 1, 25, vocab_size)\n",
        "      \n",
        "      predict.append(int(torch.argmax(output,-1)[0][t])) \n",
        "      if predict[-1]==V.vocab.stoi['<eos>']:\n",
        "        break\n",
        "      tar=[[V.vocab.stoi['<sos>']]+predict+[V.vocab.stoi['<pad>']]*(kargs['max_len']-(t+2))] # ( 1, max_len )\n",
        "      tar = torch.LongTensor(tar).to(device)\n",
        "\n",
        "    return predict[:-1] # ( 답변 길이, ) # 맨 마지막 <eos> 제거"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcKZcVlkqSuH"
      },
      "source": [
        "### 테스트"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTb8-rVoZysC",
        "outputId": "cc8e06f0-07c5-4d00-f097-6c50f9f13d8d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([2.])"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.Tensor([V.vocab.stoi['<sos>']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-ELiDNVZ_Tu",
        "outputId": "8e5839e5-12f0-4622-ec70-3ba97065eced"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[2., 5., 7.]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 1, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ],
      "source": [
        "a=torch.Tensor([[2,5]])\n",
        "b=torch.Tensor([[5,7]])[:,-1]\n",
        "c=torch.cat([a,b[None,:]],-1)\n",
        "print(c)\n",
        "padding_mask(c).size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGQY7Rf_fl9U",
        "outputId": "b082366f-ed32-423c-d2f1-057d43219849"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "그래\n"
          ]
        }
      ],
      "source": [
        "a=torch.Tensor([[[1,2,3,4,5,4,3,2,1],[1,2,3,4,5,4,3,2,8]]])\n",
        "b=torch.argmax(a,-1)[:,-1]\n",
        "if b==8:\n",
        "  print('그래')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tar=[[V.vocab.stoi['<sos>']]+[V.vocab.stoi['<pad>']]*(kargs['max_len']-1)]\n",
        "torch.LongTensor(tar)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iai7wj3XDhkR",
        "outputId": "e220b871-f810-4446-ef7b-9d136135fa6e"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1]])"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a=torch.Tensor([[[1,2,3,4,5,4,3,2,1],[1,2,3,4,5,4,3,2,8]]])\n",
        "int(torch.argmax(a,-1)[0][1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OC_PAViqFRiG",
        "outputId": "7e6aeaef-4469-4493-f07b-8ea92b1781e9"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hn2LY5Y1qUBS"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "he-4vXDbizIM"
      },
      "outputs": [],
      "source": [
        "## hyperparameter\n",
        "BATCH_SIZE=2\n",
        "EPOCH=30\n",
        "MAX_LEN=25\n",
        "kargs={'max_len':MAX_LEN,\n",
        "       'emb_dim':512,\n",
        "       'd_model':512,\n",
        "       'num_layers':2,\n",
        "       'num_heads':8,\n",
        "       'ffn_dim':2048,\n",
        "       'vocab_size':len(V.vocab),\n",
        "       'p_rate':0.1\n",
        "       }\n",
        "\n",
        "device='cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-VqjmNrr1qu"
      },
      "source": [
        "### Compile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "YGNJlfT8r31W"
      },
      "outputs": [],
      "source": [
        "model = Transformer(**kargs).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(),1e-4)\n",
        "criterion = nn.CrossEntropyLoss(reduction='none',ignore_index=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1yh4eLVBvPzI"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "C-BX1bxfv3nG"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "IrzZw_fmvSSv"
      },
      "outputs": [],
      "source": [
        "def loss_padding(predict,label):\n",
        "  # 패딩을 loss 계산에서 지울 것이다. => label에서 index가 1인 부분에 대한 mask를 생성해서 곱해주자 / 추가적으로 accuracy 계산에서도 사용할 mask를 반환\n",
        "    mask=torch.ones(predict.size()).to(device)\n",
        "    mask=torch.logical_not(mask==label)\n",
        "    \n",
        "    return ((predict*mask).sum())/mask.sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyzALD3a--6-"
      },
      "source": [
        "### 테스트"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "0X7o05GG8osB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b7c1755-1b46-4960-a874-cc35e36c2012"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 9470, 25])\n",
            "tensor([[ 9.1000,  9.7201,  8.8066,  9.6515,  9.1926,  9.5787,  9.5513, 10.4012,\n",
            "         10.0843,  8.6300,  8.9856,  9.3027,  8.9867,  9.1168,  8.4909,  8.7824,\n",
            "          8.5005,  8.9317,  9.1824,  8.5907,  8.9038,  8.5376,  8.8263,  8.9623,\n",
            "          8.5800],\n",
            "        [ 9.9087,  9.9234,  9.5817,  9.2101, 10.4605, 10.3115,  8.8544,  8.7652,\n",
            "          9.0175,  8.7727,  8.7922,  8.7394,  8.5367,  8.5548,  8.9932,  8.8722,\n",
            "          8.6833,  8.6966,  8.8398,  9.2897,  8.6282,  8.6513,  8.8600,  8.6779,\n",
            "          8.6033]], grad_fn=<ViewBackward0>)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(9.6988, grad_fn=<DivBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "output=model(batch.question.to(device),batch.answer.to(device))\n",
        "print(output.size())\n",
        "loss=criterion(output,batch.label.to(device))\n",
        "print(loss)\n",
        "loss_padding(loss,batch.answer.to(device))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmvt7iMP_AmF"
      },
      "source": [
        "## train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "5op1byqmwIjB"
      },
      "outputs": [],
      "source": [
        "def train(model,optimizer,criterion,train_iter):\n",
        "  model.train()\n",
        "\n",
        "  for batch in tqdm(train_iter):\n",
        "    enc_input=batch.question.to(device)\n",
        "    dec_input=batch.answer.to(device)\n",
        "    label=batch.label.to(device)\n",
        "\n",
        "    loss=model(enc_input,dec_input) # ( batch_size, vocab_size, max_len )\n",
        "    loss= loss_padding(criterion(loss,label),label)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7byvTrNxUZF"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "VIi4fGcJxQJ2"
      },
      "outputs": [],
      "source": [
        "def acc_padding(logit,label):\n",
        "  # padding을 포함하지 않은 맞춘 개수를 반환 및 acc,loss 계산에 포함되는 전체 token 개수 return\n",
        "  acc=(logit.max(2)[1]==label) # 맞춘 개수 \n",
        "  print(logit.max(2)[1])\n",
        "  mask=torch.ones(label.size()).to(device)\n",
        "  mask=torch.logical_not(mask==label)\n",
        "  acc=mask*acc # masking : padding에 해당하는 맞춘 개수는 제외\n",
        "\n",
        "  acc=acc.sum() # 계산에 포함되는 batch내의 맞춘 token의 개수\n",
        "  size=mask.sum() # 계산에 포함되는 batch내의 모든 token의 개수\n",
        "  \n",
        "  return acc/size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "PYXSI3-4ytv9"
      },
      "outputs": [],
      "source": [
        "def evaluation(model,optimizer,criterion,val_iter):\n",
        "  model.eval()\n",
        "\n",
        "  total_loss,acc,size=0,0,0\n",
        "  \n",
        "  for batch in tqdm(val_iter):\n",
        "    enc_input=batch.question.to(device)\n",
        "    dec_input=batch.answer.to(device)\n",
        "    label=batch.label.to(device)\n",
        "\n",
        "    logit=model(enc_input,dec_input) # ( batch_size, vocab_size, max_len )\n",
        "    loss = loss_padding(criterion(logit,label),label) # ( batch_size, max_len )\n",
        "    total_loss+=loss\n",
        "\n",
        "    logit=logit.transpose(1,2) # ( batch_size, max_len, vocab_size )\n",
        "    acc = acc_padding(logit,label)\n",
        "    acc+=acc\n",
        "\n",
        "  avg_loss=total_loss/len(val_iter)\n",
        "  avg_acc=acc/len(val_iter)\n",
        "\n",
        "  return avg_loss, avg_acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-fWk1lh0O53"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mCtxuuRhzZ3m"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6E9SGiEv0UHp"
      },
      "outputs": [],
      "source": [
        "best_val_loss = None\n",
        "\n",
        "for e in range(EPOCH):\n",
        "  train(model,optimizer,criterion,train_iter)\n",
        "  val_loss,val_acc = evaluation(model,optimizer,criterion,val_iter)\n",
        "\n",
        "  print(\"Epoch : {} | val_loss : {:5.2f} , val_accuracy : {:5.2f}\".format(e+1,val_loss.item(),val_acc.item()))\n",
        "\n",
        "  if not best_val_loss or best_val_loss>val_loss:\n",
        "    os.makedirs('best_weight',exist_ok=True)\n",
        "    torch.save(model.state_dict(),'./best_weight/best_performance_weight.pt')\n",
        "    best_val_loss=val_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDcdmqyHUkAJ"
      },
      "source": [
        "# Chatbot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "FhZ0Om4UUjWB"
      },
      "outputs": [],
      "source": [
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "YsOeOXeVDB2b"
      },
      "outputs": [],
      "source": [
        "# 실제 사용\n",
        "# model output ( batch_size, vocab_size, max_len==25 )\n",
        "\n",
        "model.load_state_dict(torch.load('./best_weight/best_performance_weight.pt',map_location=torch.device('cpu')))\n",
        "\n",
        "def chatbot(sentence):\n",
        "  input=re.sub('[^ a-zA-Z0-9가-힣]',\"\",sentence).split()\n",
        "\n",
        "  if len(input)<MAX_LEN:\n",
        "    input=input+['<pad>']*(MAX_LEN-len(input)) # padding\n",
        "  else:\n",
        "    input=input[:MAX_LEN] # truncate\n",
        "\n",
        "  input=torch.LongTensor([V.vocab.stoi[word] for word in input])[None,:].to(device) # sentence to index ( 1, max_len ) \n",
        "\n",
        "  predict=model.inference(input,14)\n",
        "\n",
        "  return \" \".join([V.vocab.itos[word] for word in predict][1:]) # <sos> 제거"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 테스트"
      ],
      "metadata": {
        "id": "BhJuzyVJI19V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1KiMqlp-Xict",
        "outputId": "7cdf7853-02a6-41e1-9c79-1745a8f1af66"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 184, 3340,  555, 1549, 3340,    1,    1,    1,    1,    1,    1,    1,\n",
              "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "            1]], device='cuda:0')"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input=re.sub('[^ a-zA-Z0-9가-힣]',\"\",sentence).split()\n",
        "\n",
        "if len(input)<MAX_LEN:\n",
        "    input=input+['<pad>']*(MAX_LEN-len(input)) # padding\n",
        "else:\n",
        "    input=input[:MAX_LEN] # truncate\n",
        "\n",
        "input=torch.LongTensor([V.vocab.stoi[word] for word in input])[None,:].to(device)\n",
        "input"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 사용"
      ],
      "metadata": {
        "id": "EuqyxnvyI3H6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "hT7u541GVlO4",
        "outputId": "0da6695e-29a9-4226-f905-ebf5f55a7bd4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "안녕\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'당신의 잘못이 아니에요 너무 무거운 짐을 덜어보세요'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 127
        }
      ],
      "source": [
        "sent=input()\n",
        "chatbot(sent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "jPPQmfOuVtw2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "c5b78409-ab29-43da-c956-dbcaa18cdfac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "너는 누구니\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'거예요 그러다가 이랬다 저랬다 크기가 다르겠지만 좋아하는 죽을 티나요 동료가 있을 듯'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 128
        }
      ],
      "source": [
        "sent=input()\n",
        "chatbot(sent)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent=input()\n",
        "chatbot(sent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "fa6Rc9P2JNtg",
        "outputId": "4874db7c-556d-4bff-ef60-0add9c2620d3"
      },
      "execution_count": 129,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "무슨 말을 하는 거니\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'고백이 쓴 게 먼저일 짧아요 되요 있으면 피하세요'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent=input()\n",
        "chatbot(sent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "MbnmXbl8JP3e",
        "outputId": "b689db24-732a-40d2-dd15-2d2a7c076ea3"
      },
      "execution_count": 130,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "헛소리 하지마 임마\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'겨울 나길 호감을 표현해보세요'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent=input()\n",
        "chatbot(sent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "eVh0iGpgJR8u",
        "outputId": "2d386929-38eb-4b57-d6c6-019b87a06ac8"
      },
      "execution_count": 131,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "알았어\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'하기도 합니다'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent=input()\n",
        "chatbot(sent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "BHtfZY3OJUdm",
        "outputId": "d1575f79-3281-4d13-9b31-433f1e0d0084"
      },
      "execution_count": 132,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "학습이 아직 덜 되었나 보네\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'마시기 전에 두근거림을 좋아하나 봐요 곧 기운낼 수 있어요라고 감히 말해 달라고'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UTikE06eJXTW"
      },
      "execution_count": 132,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "dni9UQeR_s9A",
        "FPsgVrZh_0U5",
        "m946s_wt6xdd",
        "NU8Gw5LxDET5",
        "jcKZcVlkqSuH"
      ],
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1Vc3jZml7wS5JTvknhAA6YLaCPkYpVef0",
      "authorship_tag": "ABX9TyOQCNcqrMkF64sUegjiJnXO",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}